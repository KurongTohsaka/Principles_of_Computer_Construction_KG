{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T02:36:48.042832Z",
     "start_time": "2024-09-15T02:36:48.036887Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\first_epoch_trainset_v7.json', 'r') as f1:\n",
    "    first = json.loads(f1.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\second_epoch_trainset_v3.json', 'r') as f2:\n",
    "    second = json.loads(f2.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\third_epoch_trainset_v3.json', 'r') as f3:\n",
    "    third = json.loads(f3.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\forth_epoch_trainset_v3.json', 'r') as f4:\n",
    "    forth = json.loads(f4.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\fifth_epoch_trainset_v3.json', 'r') as f5:\n",
    "    fifth = json.loads(f5.read())\n",
    "\n",
    "final_trainset = first + second + third + forth + fifth\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\ner_trainset_v1.json', 'w') as f:\n",
    "    f.write(json.dumps(final_trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4147"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unlabled_shots_from_corpus(corpus: dict, blank_seq: list):\n",
    "    for n in blank_seq:\n",
    "        for idx in range(n * 8, (n + 1) * 8):\n",
    "            try:\n",
    "                del corpus[str(idx)]\n",
    "            except:\n",
    "                pass\n",
    "    return corpus\n",
    "\n",
    "def remove_null_dict_from_labels(corpus_labels: dict, blank_seq: list):\n",
    "    for n in blank_seq:\n",
    "        del corpus_labels[n]\n",
    "    return corpus_labels\n",
    "\n",
    "def initial_dataset(corpus: dict, corpus_labels: dict):\n",
    "    dataset_dict = {\"corpus\": [], \"labels\": []}\n",
    "    for key, value in corpus.items():\n",
    "        dataset_dict['corpus'].append(value)\n",
    "    for key, value in corpus_labels.items():\n",
    "        for i in value:\n",
    "            dataset_dict['labels'].append(i)\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels(dataset_dict: dict):\n",
    "    dataset_dict['new_labels'] = []\n",
    "    for i, sentence in enumerate(dataset_dict['corpus']):\n",
    "        tmp = ['O'] * len(sentence)\n",
    "        labels = dataset_dict['labels'][i]['output']\n",
    "        for label in labels:\n",
    "            for idx in range(label['start'], label['end']):\n",
    "                tmp[idx] = f'I-{label['type']}'\n",
    "        dataset_dict['new_labels'].append(tmp)\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"G:\\python_codes\\Principles_of_Computer_Construction_KG\\corpus\\texts_sentence.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = json.loads(f.read())\n",
    "\n",
    "with open(r\"G:\\python_codes\\Principles_of_Computer_Construction_KG\\corpus\\corpus_labels.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus_labels = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_seq = []\n",
    "for k, v in corpus_labels.items():\n",
    "    if not v:\n",
    "        blank_seq.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus = remove_unlabled_shots_from_corpus(corpus, blank_seq)\n",
    "new_corpus_labels = remove_null_dict_from_labels(corpus_labels, blank_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = initial_dataset(new_corpus, new_corpus_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict['corpus'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict['labels'][0]['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_dict['corpus']) == len(dataset_dict['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练集：验证集：测试集 = 8：1：1\n",
    "- 先随机从数据集中取出1000条数据\n",
    "- 对这1000条数据进行校对（设立一个新的标签PCC。没有识别出来的要标记出来，改正识别错的）\n",
    "- 校对完之后，建立一个词典\n",
    "- 用这1000条数据进行预训练\n",
    "- 再拿出1000条数据用第一次训练后的模型进行标注，再进行一次人工标注后，更新词典。到此为止完成第一次迭代，下面重复这个过程，直到训练集的数据全部标注完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_slice = int(len(dataset_dict['corpus']) * 0.8)\n",
    "test_set_sclice = int(len(dataset_dict['corpus']) * 0.1)\n",
    "validset_slice = len(dataset_dict['corpus']) - trainset_slice - test_set_sclice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset.json', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_trainset = json.loads(f.read())\n",
    "all_idx = list(range(trainset_slice))\n",
    "first_epoch_idx = first_epoch_trainset['ids']\n",
    "second_epoch_idx = list(\n",
    "    random.sample([i for i in all_idx if i not in first_epoch_idx], 1000)\n",
    ")\n",
    "third_epoch_idx = list(\n",
    "    random.sample([i for i in all_idx if i not in (first_epoch_idx + second_epoch_idx)], 1000)\n",
    ")\n",
    "forth_epoch_idx = list(\n",
    "    random.sample([i for i in all_idx if i not in (first_epoch_idx + second_epoch_idx + third_epoch_idx)], 1000)\n",
    ")\n",
    "fifth_epoch_idx = list(set(all_idx) - set(first_epoch_idx) - set(second_epoch_idx) - set(third_epoch_idx) - set(forth_epoch_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_epoch_trainset(idx, dataset_dict, epoch='first'):\n",
    "    epoch_trainset = {\n",
    "        'ids': idx,\n",
    "        \"corpus\": [dataset_dict[\"corpus\"][i] for i in idx],\n",
    "        \"labels\": [dataset_dict[\"labels\"][i] for i in idx],\n",
    "    }\n",
    "    with open(f'G:/python_codes/Principles_of_Computer_Construction_KG/output/{epoch}_epoch_trainset.json', 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(epoch_trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_epoch_trainset(second_epoch_idx, dataset_dict, epoch='second')\n",
    "generate_epoch_trainset(third_epoch_idx, dataset_dict, epoch='third')\n",
    "generate_epoch_trainset(forth_epoch_idx, dataset_dict, epoch='forth')\n",
    "generate_epoch_trainset(fifth_epoch_idx, dataset_dict, epoch='fifth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(fifth_epoch_idx) + len(forth_epoch_idx) + len(third_epoch_idx) + len(second_epoch_idx) + len(first_epoch_idx)) == len(all_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = {\n",
    "        'corpus': dataset_dict['corpus'][trainset_slice:trainset_slice + test_set_sclice],\n",
    "        'labels': dataset_dict['labels'][trainset_slice:trainset_slice + test_set_sclice],\n",
    "    }\n",
    "validset = {\n",
    "        'corpus': dataset_dict['corpus'][trainset_slice + test_set_sclice:],\n",
    "        'labels': dataset_dict['labels'][trainset_slice + test_set_sclice:],\n",
    "    }\n",
    "\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(test_set))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_epoch_trainset_idx = list(\n",
    "    random.sample(range(0, trainset_slice), 1000)\n",
    ")\n",
    "first_epoch_trainset = {\n",
    "    'ids': first_epoch_trainset_idx,\n",
    "    \"corpus\": [dataset_dict[\"corpus\"][i] for i in first_epoch_trainset_idx],\n",
    "    \"labels\": [dataset_dict[\"labels\"][i] for i in first_epoch_trainset_idx],\n",
    "}\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(first_epoch_trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v2.json', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_trainset = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_template = {\n",
    "    \"data\": {\"text\": None},\n",
    "    \"predictions\": [\n",
    "        {\n",
    "            \"model_version\": \"nlp_raner_named-entity-recognition_chinese-large-generic\",\n",
    "            \"score\": 0.94,\n",
    "            \"result\": [],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "result_template = {\n",
    "        'id': None,\n",
    "        'from_name': 'label',\n",
    "        'to_name': 'text',\n",
    "        \"type\": \"labels\",\n",
    "        \"value\": {\n",
    "              \"start\": None,\n",
    "              \"end\": None,\n",
    "              \"score\": None,  # prob\n",
    "              \"text\": None,  # span\n",
    "              \"labels\": [\n",
    "                None  # type\n",
    "              ]\n",
    "            }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pre_labeled_dataset(dataset: dict):\n",
    "    pre_labeled_data = []\n",
    "    id_count = 1\n",
    "\n",
    "    for i, labels in enumerate(dataset[\"labels\"]):\n",
    "\n",
    "        json_template_tmp = {\n",
    "            \"data\": {\"text\": None},\n",
    "            \"predictions\": [\n",
    "                {\n",
    "                    \"model_version\": \"nlp_raner_named-entity-recognition_chinese-large-generic\",\n",
    "                    \"score\": 0.86,\n",
    "                    \"result\": [],\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        json_template_tmp[\"data\"][\"text\"] = dataset[\"corpus\"][i]\n",
    "\n",
    "        for label in labels[\"output\"]:\n",
    "\n",
    "            json_template_tmp[\"predictions\"][0][\"result\"].append(\n",
    "                {\n",
    "                    \"id\": str(id_count),\n",
    "                    \"from_name\": \"label\",\n",
    "                    \"to_name\": \"text\",\n",
    "                    \"type\": \"labels\",\n",
    "                    \"value\": {\n",
    "                        \"start\": label[\"start\"],\n",
    "                        \"end\": label[\"end\"],\n",
    "                        \"score\": label[\"prob\"],  # prob\n",
    "                        \"text\": label[\"span\"],  # span\n",
    "                        \"labels\": [label[\"type\"]],  # type\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "            id_count += 1\n",
    "\n",
    "        pre_labeled_data.append(json_template_tmp)\n",
    "\n",
    "    return pre_labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '随机替换随机替换策略实际上是不要什么算法，从特定的行位置中随机地选取一行换出即可',\n",
       " 'id': 3594,\n",
       " 'label': [{'start': 0, 'end': 4, 'text': '随机替换', 'labels': ['TECH']},\n",
       "  {'start': 18, 'end': 20, 'text': '算法', 'labels': ['ALG']},\n",
       "  {'start': 4, 'end': 8, 'text': '随机替换', 'labels': ['TECH']},\n",
       "  {'start': 26, 'end': 27, 'text': '位', 'labels': ['DATA']}],\n",
       " 'annotator': 1,\n",
       " 'annotation_id': 5027,\n",
       " 'created_at': '2024-08-01T12:11:03.657045Z',\n",
       " 'updated_at': '2024-08-01T12:11:03.657045Z',\n",
       " 'lead_time': 2.057}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\ner_trainset_v1.json', 'r') as f:\n",
    "    ner_dataset = json.loads(f.read())\n",
    "\n",
    "dataset[1]"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T02:38:35.655472Z",
     "start_time": "2024-09-15T02:38:35.635606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset\\validset_v7.json', 'r', encoding='utf-8') as f:\n",
    "    ner_validset = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\testset\\test_set_v7.json', 'r', encoding='utf-8') as f:\n",
    "    ner_testset = json.loads(f.read())"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T02:38:53.745276Z",
     "start_time": "2024-09-15T02:38:53.739590Z"
    }
   },
   "source": [
    "def generate_re_pre_annotated_dataset(dataset):\n",
    "    pre_labeled_data = []\n",
    "    id_count = 1\n",
    "\n",
    "    for i, item in enumerate(dataset):\n",
    "\n",
    "        json_template_tmp = {\n",
    "            \"data\": {\"text\": None},\n",
    "            \"predictions\": [\n",
    "                {\n",
    "                    \"model_version\": \"\",\n",
    "                    \"score\": 0,\n",
    "                    \"result\": [],\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        json_template_tmp[\"data\"][\"text\"] = dataset[i]['text']\n",
    "\n",
    "        if item.get('label'):\n",
    "            for label in item[\"label\"]:\n",
    "                json_template_tmp[\"predictions\"][0][\"result\"].append(\n",
    "                    {\n",
    "                        \"id\": str(id_count),\n",
    "                        \"from_name\": \"label\",\n",
    "                        \"to_name\": \"text\",\n",
    "                        \"type\": \"labels\",\n",
    "                        \"value\": {\n",
    "                            \"start\": label[\"start\"],\n",
    "                            \"end\": label[\"end\"],\n",
    "                            \"score\": 0.1,  # prob\n",
    "                            \"text\": label[\"text\"],  # span\n",
    "                            \"labels\": label[\"labels\"],  # type\n",
    "                        },\n",
    "                    }\n",
    "                )\n",
    "                id_count += 1\n",
    "\n",
    "        pre_labeled_data.append(json_template_tmp)\n",
    "\n",
    "    return pre_labeled_data"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T02:40:05.667224Z",
     "start_time": "2024-09-15T02:40:05.639523Z"
    }
   },
   "source": [
    "re_pre_annotated_validset = generate_re_pre_annotated_dataset(ner_validset)\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset\\re_pre_annotated_validset.json', 'w') as f:\n",
    "    f.write(json.dumps(re_pre_annotated_validset))"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T02:40:06.951381Z",
     "start_time": "2024-09-15T02:40:06.935850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "re_pre_annotated_testset = generate_re_pre_annotated_dataset(ner_testset)\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\testset\\re_pre_annotated_testset.json', 'w') as f:\n",
    "    f.write(json.dumps(re_pre_annotated_testset))"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_v2_pre_labeled_data.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(generate_pre_labeled_dataset(first_epoch_trainset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\pre_labeled_test_set.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(generate_pre_labeled_dataset(test_set)))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\pre_labeled_validset.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(generate_pre_labeled_dataset(validset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v2.json', 'r', encoding='utf-8') as f:\n",
    "    test_set_v2 = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v2.json', 'r', encoding='utf-8') as f:\n",
    "    validset_v2 = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\pre_labeled_test_set_v2.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(generate_pre_labeled_dataset(test_set_v2)))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\pre_labeled_validset_v2.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(generate_pre_labeled_dataset(validset_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v6.json', 'r', encoding='utf-8') as f:\n",
    "    test_set_v6 = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v6.json', 'r', encoding='utf-8') as f:\n",
    "    validset_v6 = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\pre_labeled_test_set_v6.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(generate_pre_labeled_dataset(test_set_v6)))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\pre_labeled_validset_v6.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(generate_pre_labeled_dataset(validset_v6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v6.json', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_trainset_v6 = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_v6_pre_labeled_data.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(generate_pre_labeled_dataset(first_epoch_trainset_v6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\second_epoch_trainset_v2.json', 'r', encoding='utf-8') as f:\n",
    "#     second_epoch_trainset_v2 = json.loads(f.read())\n",
    "# with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\third_epoch_trainset_v2.json', 'r', encoding='utf-8') as f:\n",
    "#     third_epoch_trainset_v2 = json.loads(f.read())\n",
    "# with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\forth_epoch_trainset_v2.json', 'r', encoding='utf-8') as f:\n",
    "#     forth_epoch_trainset_v2 = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\fifth_epoch_trainset_v2.json', 'r', encoding='utf-8') as f:\n",
    "    fifth_epoch_trainset_v2 = json.loads(f.read())\n",
    "\n",
    "# 注意输出路径\n",
    "# with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\second_epoch_v2_pre_labeled_data.json', 'w', encoding='utf-8') as f:\n",
    "#     f.write(json.dumps(generate_pre_labeled_dataset(second_epoch_trainset_v2)))\n",
    "# with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\third_epoch_v2_pre_labeled_data.json', 'w', encoding='utf-8') as f:\n",
    "#     f.write(json.dumps(generate_pre_labeled_dataset(third_epoch_trainset_v2)))\n",
    "# with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\forth_epoch_v2_pre_labeled_data.json', 'w', encoding='utf-8') as f:\n",
    "#     f.write(json.dumps(generate_pre_labeled_dataset(forth_epoch_trainset_v2)))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\trainset\\fifth_epoch_v2_pre_labeled_data.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(generate_pre_labeled_dataset(fifth_epoch_trainset_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_set = set()\n",
    "for i, labels in enumerate(first_epoch_trainset['labels']):\n",
    "    entitys = [label['span'] for label in labels['output']]\n",
    "    entitys_type = [label['type'] for label in labels['output']]\n",
    "    for item in dict(zip(entitys, entitys_type)).items():\n",
    "        entity_set.add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list = list(entity_set)\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(entity_list))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(entity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
