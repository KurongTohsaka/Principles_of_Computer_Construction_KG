{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:27:47.685610Z",
     "start_time": "2024-09-24T11:27:43.741516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "a591de6a71392af",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:28:02.848462Z",
     "start_time": "2024-09-24T11:28:02.842602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 标签映射\n",
    "label_to_id = {\n",
    "    \"COMP\": 0, \"DATA\": 1, \"ARCH\": 2, \"PROG\": 3, \"PROT\": 4,\n",
    "    \"PERF\": 5, \"STOR\": 6, \"ALG\": 7, \"IO\": 8, \"TECH\": 9, \"INST\": 10\n",
    "}\n",
    "\n",
    "# 关系抽取的标签设计：用一个1xN维向量（N为分类数量）表示一个段落的所有关系。如句子中存在这两种关系，contain(e1,e2)映射为0, contain(e1,e3)映射为1，related(e1,e2)映射为2，related(e1,e3)映射为3，那么标签就是[1, 1,1,1]。之后就以此类推\n",
    "relation_to_id = {\n",
    "    \"contain\": 0, \"sequence\": 1, \"synonymy\": 2, \"related\": 3, \"attribute\": 4\n",
    "}"
   ],
   "id": "b8647d10cdb2dd1c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:28:04.431292Z",
     "start_time": "2024-09-24T11:28:04.425244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RelationExtractionDataset(Dataset):\n",
    "    def __init__(self, json_filename: str):\n",
    "        with open(json_filename, 'r', encoding='utf-8') as f:\n",
    "            data = json.loads(f.read())\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ],
   "id": "b06d01c74dbca5a6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:30:01.683034Z",
     "start_time": "2024-09-24T11:30:01.671499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_data(batch_samples, num_relations, max_entities):\n",
    "    sentences = []\n",
    "    relation_labels = []\n",
    "    masks = []\n",
    "\n",
    "    for item in batch_samples:\n",
    "        entity_text_to_id = {}\n",
    "        sentence = item['sentence']\n",
    "        entities = item['entities']\n",
    "        relations = item['relations']\n",
    "\n",
    "        # 按照实体的起始位置进行排序，确保替换时不会重叠\n",
    "        entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
    "\n",
    "        # 加入实体标记\n",
    "        for idx, entity in enumerate(entities):\n",
    "            entity_text = entity['text']\n",
    "            entity_start = entity['start']\n",
    "            entity_end = entity['end']\n",
    "            entity_id = f\"{entity_text}_{entity_start}\"\n",
    "            entity_text_to_id[entity_id] = idx  # 使用索引作为ID\n",
    "            entity_label = f\"E{len(entities) - idx}\"\n",
    "            sentence = sentence[:entity_start] + f\"[{entity_label}S]\" + sentence[\n",
    "                                                                        entity_start:entity_end] + f\"[{entity_label}E]\" + sentence[\n",
    "                                                                                                                          entity_end:]\n",
    "        sentences.append(sentence)\n",
    "\n",
    "        # 初始化关系标签矩阵\n",
    "        # 1381 才是正确的维度！！！\n",
    "        relation_vector = np.zeros((1, num_relations * max_entities * (max_entities - 1) // 2 + 1), dtype=int)\n",
    "\n",
    "        # 转换关系标签\n",
    "        # 建立一个实体id和相应位置实体的映射表\n",
    "        # 然后根据实体id再去把对应的实体关系置1，这才是正确的操作\n",
    "        # 下面的这份代码，操作逻辑乱七八糟\n",
    "        # {'双倍数据率结构_0': 1, '预取结构_14': 2}\n",
    "        entity_ids = {}\n",
    "        for i, key in enumerate(entity_text_to_id.keys()):\n",
    "            entity_ids[key] = len(entity_text_to_id) - i\n",
    "\n",
    "        if not relations:\n",
    "            relation_vector[0, -1] = 1\n",
    "        else:\n",
    "            for relation in relations:\n",
    "                head = relation[0]\n",
    "                relation_label = relation[1]\n",
    "                tail = relation[2]\n",
    "\n",
    "                # 这几句涉及多关系的实体重叠问题，必须要考虑到\n",
    "                # 获取实体的起始位置\n",
    "                head_entity_start = next(entity['start'] for entity in entities if entity['text'] == head)\n",
    "                tail_entity_start = next(entity['start'] for entity in entities if entity['text'] == tail)\n",
    "                # 通过位置来区分重叠实体\n",
    "                head_entity = f\"{head}_{head_entity_start}\"\n",
    "                tail_entity = f\"{tail}_{tail_entity_start}\"\n",
    "                # 查找实体id，以确认标签位置\n",
    "                # 标签位置公式，对于关系R_x(E_y,E_z)\n",
    "                # entity_pair_start = (y-1)*(2*mas_entities-y)/2 + (z-y-1)\n",
    "                # 标签位置 = entity_pair_start * num_relations + x\n",
    "                if head_entity in entity_text_to_id and tail_entity in entity_text_to_id:\n",
    "                    head_entity_id = entity_ids[head_entity]\n",
    "                    tail_entity_id = entity_ids[tail_entity]\n",
    "                    relation_type = relation_to_id[relation_label]\n",
    "                    if tail_entity_id < head_entity_id:\n",
    "                        entity_pair = (tail_entity_id, head_entity_id)\n",
    "                    else:\n",
    "                        entity_pair = (head_entity_id, tail_entity_id)\n",
    "                    # (1,0)自然是没有的\n",
    "                    # 这里涉及到关系是单向还是双向的，但是双向的关系之前已经被我处理为了两个单向，但是吧...，要是考虑单向关系会导致现有的标签维度翻倍\n",
    "                    # 不涉及单向关系了，将实体对全部设置为标准形式\n",
    "                    # 下面的两个公式计算似乎有误，还需要检查验证\n",
    "                    # entity_pair_start = generate_entity_pair_positions(max_entities, num_relations)[entity_pair]\n",
    "                    entity_pair_start = (entity_pair[0] - 1) * (2 * max_entities - entity_pair[0]) + (\n",
    "                                entity_pair[1] - entity_pair[0] - 1)\n",
    "                    label_idx = entity_pair_start * num_relations + relation_type\n",
    "                    relation_vector[0, int(label_idx)] = 1\n",
    "\n",
    "        relation_labels.append(relation_vector)\n",
    "\n",
    "        # 生成掩码\n",
    "        mask = np.zeros((1, num_relations * max_entities * (max_entities - 1) // 2 + 1), dtype=int)\n",
    "        mask[0, -1] = 1\n",
    "\n",
    "        for i in range(len(entities)):\n",
    "            for j in range(i + 1, len(entities)):\n",
    "                for k in range(num_relations):\n",
    "                    index = i * (max_entities - 1) * num_relations + j * num_relations + k\n",
    "                    mask[0, index] = 1\n",
    "\n",
    "        masks.append(mask)\n",
    "\n",
    "    return sentences, relation_labels, masks"
   ],
   "id": "e53ff136bc673654",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:30:02.004032Z",
     "start_time": "2024-09-24T11:30:01.995631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_dataloader(dataset, tokenizer, batch_size=4, shuffle=False, max_len=512, num_relations=5, max_entities=24):\n",
    "    def collate_fn(batch_samples):\n",
    "        sentences, relation_labels, masks = preprocess_data(batch_samples, num_relations, max_entities)\n",
    "\n",
    "        batch_inputs = tokenizer(\n",
    "            sentences,\n",
    "            max_length=max_len,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': batch_inputs['input_ids'],\n",
    "            'attention_mask': batch_inputs['attention_mask'],\n",
    "            'labels': torch.tensor(relation_labels, dtype=torch.long),\n",
    "            'masks': torch.tensor(masks, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n"
   ],
   "id": "fdbd932710afc517",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:30:03.190801Z",
     "start_time": "2024-09-24T11:30:02.780475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pretrained_model_name = 'bert-base-chinese'\n",
    "re_tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "trainset_path = r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\[banned]\\transformed_trainset.json'\n",
    "# validset_path = '/kaggle/input/re-pre-annotated-dataset/transformed_validset.json'\n",
    "# testset_path = '/kaggle/input/re-pre-annotated-dataset/transformed_testset.json'\n",
    "\n",
    "re_trainset = RelationExtractionDataset(json_filename=trainset_path)\n",
    "# re_validset = RelationExtractionDataset(json_filename=validset_path)\n",
    "# re_testset = RelationExtractionDataset(json_filename=testset_path)\n",
    "\n",
    "trainset_loader = get_dataloader(re_trainset, re_tokenizer, batch_size=1, shuffle=False)\n",
    "# validset_loader = get_dataloader(re_validset, re_tokenizer, batch_size=4, shuffle=False)\n",
    "# testset_loader = get_dataloader(re_testset, re_tokenizer, batch_size=4, shuffle=False)"
   ],
   "id": "b8f74f0174ea0c06",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:30:03.835463Z",
     "start_time": "2024-09-24T11:30:03.825521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, batch in enumerate(trainset_loader):\n",
    "    if i == 0:\n",
    "        print(batch['input_ids'])\n",
    "        print(\"Label: \",batch['labels'])\n",
    "        print(batch['labels'].shape)\n",
    "        print(\"Mask: \", batch['masks'])\n",
    "        print(batch['masks'].shape)\n",
    "        break"
   ],
   "id": "44f170983c06edcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101,  138,  100,  140, 1352,  945, 3144, 2945, 4372, 5310, 3354,  138,\n",
      "          100,  140, 3315, 6574,  677, 3221,  671,  702,  156,  138,  100,  140,\n",
      "         7564, 1357, 5310, 3354,  138,  100,  140, 8024, 1963, 1745, 2792, 4850,\n",
      "          102]])\n",
      "Label:  tensor([[[1, 0, 0,  ..., 0, 0, 0]]])\n",
      "torch.Size([1, 1, 1381])\n",
      "Mask:  tensor([[[0, 0, 0,  ..., 0, 0, 1]]])\n",
      "torch.Size([1, 1, 1381])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d3e06823baa1e0c0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
